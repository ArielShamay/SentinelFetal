"""
MOMENT Feature Extractor Module.

Implements the MOMENT foundation model integration for CTG embedding extraction.

MOMENT (Multi-task Originator for Multivariate Time-series) is a Transformer model
trained on millions of time series from diverse domains. It can identify:
    - Anomalies (sudden changes)
    - Trends (gradual increases/decreases)
    - Periodicity (repeating patterns)
    - Variance changes

Zero-Shot Mode:
    Gen3.5 uses MOMENT without fine-tuning. The model acts as a feature extractor,
    outputting 1024-dimensional embeddings that capture the signal's characteristics.

Technical Specifications:
    - Model: AutonLab/MOMENT-1-large
    - Parameters: 385 million
    - Embedding dimension: 1024
    - Patch size: 64 samples (16 seconds at 4Hz)
    - Maximum input: 512 patches = 8,192 samples (~34 minutes)
    - VRAM requirements: ~2GB (inference only)
    - Inference time: ~100-200ms per 10-minute window on CPU

References:
    - SentinelFetal Gen3.5 Technical Specification, Section 4
    - MOMENT Paper: https://arxiv.org/abs/2402.03885
"""

from __future__ import annotations

import logging
import warnings
from dataclasses import dataclass, field
from typing import List, Optional, Union

import numpy as np

# Configure module logger
logger = logging.getLogger(__name__)

# Check for MOMENT availability
MOMENT_AVAILABLE = False
TORCH_AVAILABLE = False

try:
    import torch
    TORCH_AVAILABLE = True
    
    # Check device availability
    if torch.cuda.is_available():
        DEFAULT_DEVICE = "cuda"
    elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
        DEFAULT_DEVICE = "mps"
    else:
        DEFAULT_DEVICE = "cpu"
        
    logger.info(f"PyTorch available. Default device: {DEFAULT_DEVICE}")
    
except ImportError:
    DEFAULT_DEVICE = "cpu"
    logger.warning("PyTorch not available. MOMENT encoder will use mock mode.")

try:
    from momentfm import MOMENTPipeline
    MOMENT_AVAILABLE = True
    logger.info("momentfm package available. Using real MOMENT model.")
except ImportError:
    logger.warning(
        "momentfm package not available. MOMENT encoder will use mock mode. "
        "Install with: pip install momentfm"
    )


class MomentEncoderError(Exception):
    """Raised when MOMENT encoding fails."""
    pass


@dataclass
class EmbeddingResult:
    """
    Result of embedding extraction for a single window.
    
    Attributes:
        embedding: 1024-dimensional embedding vector.
        start_idx: Start index in the original signal.
        end_idx: End index in the original signal.
        start_time_sec: Start time in seconds.
        end_time_sec: End time in seconds.
        is_mock: True if this was generated by mock mode (MOMENT not available).
    """
    
    embedding: np.ndarray
    start_idx: int
    end_idx: int
    start_time_sec: float
    end_time_sec: float
    is_mock: bool = False
    
    def __post_init__(self) -> None:
        """Validate embedding dimension."""
        if self.embedding.shape != (1024,):
            raise ValueError(
                f"Embedding must be 1024-dimensional, got {self.embedding.shape}"
            )
    
    def __repr__(self) -> str:
        mode = "MOCK" if self.is_mock else "MOMENT"
        return (
            f"EmbeddingResult({mode}, "
            f"time={self.start_time_sec:.1f}-{self.end_time_sec:.1f}s)"
        )


class MomentFeatureExtractor:
    """
    Feature extractor using MOMENT foundation model.
    
    Extracts 1024-dimensional embeddings from CTG signals using the
    AutonLab/MOMENT-1-large model in Zero-Shot mode.
    
    If MOMENT is not available (momentfm package not installed), operates in
    mock mode generating random embeddings for testing purposes.
    
    Attributes:
        EMBEDDING_DIM: Output embedding dimension (1024).
        DEFAULT_WINDOW_SIZE: Default window size in samples (2400 = 10 min @ 4Hz).
        device: Device for computation (cpu/cuda/mps).
        use_mock: Whether using mock mode (MOMENT not available).
        
    Example:
        >>> extractor = MomentFeatureExtractor(device='cuda')
        >>> embedding = extractor.extract(fhr_window)
        >>> print(f"Embedding shape: {embedding.shape}")  # (1024,)
        
    References:
        SentinelFetal Gen3.5 Technical Specification, Section 4.4
    """
    
    EMBEDDING_DIM: int = 1024
    DEFAULT_WINDOW_SIZE: int = 2400  # 10 minutes @ 4Hz
    
    def __init__(
        self, 
        device: Optional[str] = None,
        use_mock: bool = False
    ) -> None:
        """
        Initialize the MOMENT feature extractor.
        
        Args:
            device: Device for computation. Options: 'cpu', 'cuda', 'mps'.
                    If None, auto-detects best available device.
            use_mock: Force mock mode even if MOMENT is available.
                     Useful for testing.
                     
        Raises:
            MomentEncoderError: If initialization fails.
        """
        self.device = device or DEFAULT_DEVICE
        self.use_mock = use_mock or not MOMENT_AVAILABLE
        self._model = None
        
        if self.use_mock:
            logger.info(
                "MomentFeatureExtractor initialized in MOCK mode. "
                "Embeddings will be deterministic based on signal statistics."
            )
        else:
            self._load_model()
            
    def _load_model(self) -> None:
        """
        Load the MOMENT model from HuggingFace.
        
        Uses task_name='embedding' for Zero-Shot feature extraction.
        """
        logger.info("Loading MOMENT-1-large model...")
        
        try:
            self._model = MOMENTPipeline.from_pretrained(
                'AutonLab/MOMENT-1-large',
                model_kwargs={
                    'task_name': 'embedding',  # Zero-Shot embedding mode
                    'n_channels': 1  # Single channel (FHR)
                }
            )
            self._model.to(self.device)
            self._model.eval()  # Inference mode
            
            logger.info(
                f"MOMENT model loaded successfully on {self.device}"
            )
            
        except Exception as e:
            logger.error(f"Failed to load MOMENT model: {e}")
            logger.info("Falling back to mock mode")
            self.use_mock = True
            self._model = None
    
    def extract(
        self, 
        fhr: np.ndarray,
        window_size: int = None
    ) -> np.ndarray:
        """
        Extract embedding from FHR window.
        
        Args:
            fhr: FHR signal array (1D numpy array in bpm).
            window_size: Expected window size. If signal is shorter, it's padded.
                        If longer, it's truncated. Default: 2400 (10 min @ 4Hz).
                        
        Returns:
            1024-dimensional embedding vector.
            
        Raises:
            MomentEncoderError: If extraction fails.
            
        Example:
            >>> embedding = extractor.extract(fhr_window)
            >>> assert embedding.shape == (1024,)
        """
        window_size = window_size or self.DEFAULT_WINDOW_SIZE
        
        # Validate input
        if fhr is None or len(fhr) == 0:
            raise MomentEncoderError("Input FHR signal is empty or None")
        
        # Prepare signal
        fhr_prepared = self._prepare_signal(fhr, window_size)
        
        if self.use_mock:
            return self._mock_extract(fhr_prepared)
        else:
            return self._model_extract(fhr_prepared)
    
    def _prepare_signal(
        self, 
        fhr: np.ndarray, 
        window_size: int
    ) -> np.ndarray:
        """
        Prepare FHR signal for MOMENT input.
        
        Steps:
            1. Pad or truncate to window_size
            2. Replace NaN with zeros
            3. Normalize (zero mean, unit variance)
            
        Args:
            fhr: Raw FHR signal.
            window_size: Target length.
            
        Returns:
            Prepared signal array.
        """
        # Handle length
        if len(fhr) < window_size:
            # Pad with the mean (or 0 if all NaN)
            valid_values = fhr[~np.isnan(fhr)]
            pad_value = float(np.mean(valid_values)) if len(valid_values) > 0 else 0.0
            fhr = np.pad(
                fhr, 
                (0, window_size - len(fhr)), 
                mode='constant', 
                constant_values=pad_value
            )
        elif len(fhr) > window_size:
            fhr = fhr[:window_size]
        
        # Replace NaN with 0 (MOMENT doesn't handle NaN)
        fhr = np.nan_to_num(fhr, nan=0.0)
        
        # Normalize (zero mean, unit variance)
        mean = np.mean(fhr)
        std = np.std(fhr)
        if std > 1e-8:
            fhr = (fhr - mean) / std
        else:
            fhr = fhr - mean
            
        return fhr.astype(np.float32)
    
    def _model_extract(self, fhr: np.ndarray) -> np.ndarray:
        """
        Extract embedding using the real MOMENT model.
        
        Args:
            fhr: Prepared FHR signal.
            
        Returns:
            1024-dimensional embedding.
        """
        # Convert to tensor: [batch=1, channels=1, seq_len]
        x = torch.tensor(fhr, dtype=torch.float32)
        x = x.unsqueeze(0).unsqueeze(0)  # Add batch and channel dims
        x = x.to(self.device)
        
        # Inference
        with torch.no_grad():
            output = self._model(x)
            embedding = output.embeddings  # [1, 1024]
        
        return embedding.cpu().numpy().flatten()
    
    def _mock_extract(self, fhr: np.ndarray) -> np.ndarray:
        """
        Generate mock embedding based on signal statistics.
        
        Creates a deterministic embedding based on signal characteristics
        so that similar signals produce similar embeddings.
        
        Args:
            fhr: Prepared FHR signal.
            
        Returns:
            1024-dimensional mock embedding.
        """
        # Use signal statistics as seed for reproducibility
        signal_hash = hash(fhr.tobytes()) % (2**32)
        rng = np.random.RandomState(signal_hash)
        
        # Generate base random embedding
        embedding = rng.randn(self.EMBEDDING_DIM).astype(np.float32)
        
        # Encode some signal statistics into the embedding
        # This ensures similar signals produce similar embeddings
        
        # First 10 dimensions encode statistical features
        embedding[0] = float(np.mean(fhr))
        embedding[1] = float(np.std(fhr))
        embedding[2] = float(np.max(fhr) - np.min(fhr))  # Range
        embedding[3] = float(np.median(fhr))
        
        # Spectral features (simplified)
        fft_magnitudes = np.abs(np.fft.fft(fhr))[:100]
        embedding[4:9] = fft_magnitudes[:5]  # First 5 FFT components
        
        # Normalize embedding to unit norm
        norm = np.linalg.norm(embedding)
        if norm > 1e-8:
            embedding = embedding / norm
            
        return embedding
    
    def is_available(self) -> bool:
        """
        Check if real MOMENT model is available.
        
        Returns:
            True if using real MOMENT, False if using mock mode.
        """
        return not self.use_mock


def extract_embeddings_sliding_window(
    fhr: np.ndarray,
    extractor: MomentFeatureExtractor,
    sampling_rate: float = 4.0,
    window_minutes: float = 10.0,
    step_minutes: float = 1.0
) -> List[EmbeddingResult]:
    """
    Extract embeddings using sliding window over entire recording.
    
    Processes the complete FHR recording using overlapping windows to capture
    temporal evolution of the signal.
    
    Args:
        fhr: Complete FHR signal array.
        extractor: MomentFeatureExtractor instance.
        sampling_rate: Sampling frequency in Hz (default: 4.0).
        window_minutes: Window size in minutes (default: 10.0).
        step_minutes: Step size in minutes (default: 1.0).
        
    Returns:
        List of EmbeddingResult objects, one per window.
        
    Example:
        >>> extractor = MomentFeatureExtractor()
        >>> embeddings = extract_embeddings_sliding_window(fhr, extractor)
        >>> for result in embeddings:
        ...     print(f"Window {result.start_time_sec/60:.1f}-{result.end_time_sec/60:.1f} min")
        
    References:
        SentinelFetal Gen3.5 Technical Specification, Section 4.5
    """
    window_samples = int(window_minutes * 60 * sampling_rate)  # e.g., 10 * 60 * 4 = 2400
    step_samples = int(step_minutes * 60 * sampling_rate)      # e.g., 1 * 60 * 4 = 240
    
    results: List[EmbeddingResult] = []
    n_samples = len(fhr)
    
    # Check if signal is long enough
    if n_samples < window_samples:
        logger.warning(
            f"Signal too short ({n_samples} samples) for window ({window_samples}). "
            "Processing entire signal as single window."
        )
        embedding = extractor.extract(fhr, window_samples)
        results.append(EmbeddingResult(
            embedding=embedding,
            start_idx=0,
            end_idx=n_samples,
            start_time_sec=0.0,
            end_time_sec=n_samples / sampling_rate,
            is_mock=extractor.use_mock
        ))
        return results
    
    # Sliding window extraction
    window_count = 0
    for start in range(0, n_samples - window_samples + 1, step_samples):
        end = start + window_samples
        window = fhr[start:end]
        
        try:
            embedding = extractor.extract(window)
            
            results.append(EmbeddingResult(
                embedding=embedding,
                start_idx=start,
                end_idx=end,
                start_time_sec=start / sampling_rate,
                end_time_sec=end / sampling_rate,
                is_mock=extractor.use_mock
            ))
            
            window_count += 1
            
            if window_count % 10 == 0:
                logger.debug(
                    f"Processed {window_count} windows "
                    f"(time: {start/sampling_rate/60:.1f} min)"
                )
                
        except Exception as e:
            logger.warning(f"Failed to extract embedding for window {start}-{end}: {e}")
            continue
    
    logger.info(
        f"Extracted {len(results)} embeddings from {n_samples/sampling_rate/60:.1f} min recording"
    )
    
    return results


def get_device_info() -> dict:
    """
    Get information about available compute devices.
    
    Returns:
        Dictionary with device availability information.
    """
    info = {
        'torch_available': TORCH_AVAILABLE,
        'moment_available': MOMENT_AVAILABLE,
        'default_device': DEFAULT_DEVICE,
        'cuda_available': False,
        'mps_available': False,
        'cuda_device_count': 0,
    }
    
    if TORCH_AVAILABLE:
        info['cuda_available'] = torch.cuda.is_available()
        info['mps_available'] = (
            hasattr(torch.backends, 'mps') and 
            torch.backends.mps.is_available()
        )
        if info['cuda_available']:
            info['cuda_device_count'] = torch.cuda.device_count()
            info['cuda_device_name'] = torch.cuda.get_device_name(0)
    
    return info
